{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An elementary introduction to spectral audio compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we'll explore the very basics of audio compression in the spectral domain using numpy and scipy. We'll do a bit of visualization with matplotlib, but since that is covered later in the course, we'll provide those functions for you.\n",
    "\n",
    "Audio compression is a large and complex topic, and the design of a format for compressed audio such as the popular [MP3](http://en.wikipedia.org/wiki/MP3) is too complex to cover in detail here. However, we will introduce the basic tools that most such compression formats use, namely:\n",
    "\n",
    "1. Converting the input signal to the frequency domain by taking a Fast Fourier Transform (FFT).\n",
    "\n",
    "2. Dropping information in the frequency domain, resulting in a smaller amount of data.\n",
    "\n",
    "3. Reconstructing back the signal in the time domain from this smaller representation of the signal.\n",
    "\n",
    "Steps 1 and 2 above are the 'encoding' part of signal compression, and step 3 is the 'decoding' part. For this reason, the tools that perform these steps are typically referred to as signal 'codecs', short for encoders/decoders.\n",
    "\n",
    "Note that here we say 'signal': while MP3 is an audio format, the same ideas apply to the compression of digital images with formats such as JPEG and video.  Virtually all multimedia technologies we use today, from audio players to cell phones, digital cameras and YouTubeVideo, are based on sophisticated extensions and applications of these simple ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the plotting tools and importing some tools we'll need later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# we'll need some path manipulations later on\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a simple utility function to listen to audio files right in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Audio(fname):\n",
    "    \"\"\"Provide a player widget for an audio file.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    fname : string\n",
    "      Filename to be played.\n",
    "      \n",
    "    Warning\n",
    "    =======\n",
    "    \n",
    "    Browsers cache audio very aggressively. If you change an\n",
    "    audio file on disk and are trying to listen to the  new version, you \n",
    "    may want to \n",
    "    \"\"\"\n",
    "    from IPython.display import HTML, display\n",
    "    \n",
    "    # Find out file extension and deduce MIME type for audio format\n",
    "    ext = os.path.splitext(fname)[1].replace('.', '').lower()\n",
    "    mimetype = 'audio/' + ('mpeg' if ext == 'mp3' else ext)\n",
    "    \n",
    "    tpl = \"\"\"<p>{fname}:</p>\n",
    "<audio controls>\n",
    "    <source src=\"files/{fname}\" type=\"{mimetype}\">\n",
    "\n",
    "Your browser does not support the Audio element; you can play \n",
    "<a href=\"files/{fname}\">this file</a> manually.\n",
    "</audio>\n",
    "\"\"\"\n",
    "    display(HTML(tpl.format(**locals())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a convenience wrapper around `plt.specgram`, [matplotlib's spectrogram function](http://matplotlib.org/api/mlab_api.html#matplotlib.mlab.specgram), with a colorbar and control over the color limits displayed. This will make it easier to compare across different signals with the same colors for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def specgram_cbar(x, title=None, clim=(0, 80) ):\n",
    "    \"\"\"Plot spectrogram with a colorbar and range normalization.\n",
    "    \n",
    "    Call matplotlib's specgram function, with a custom figure size, \n",
    "    automatic colobar, title and custom color limits to ease \n",
    "    comparison across multiple figures.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x : array\n",
    "      One-dimensional array whose spectrogram should be plotted.\n",
    "      \n",
    "    title : string\n",
    "      Optional title for the figure.\n",
    "      \n",
    "    clim : 2-tuple\n",
    "      Range for the color limits plotted in the spectrogram.\n",
    "    \"\"\"\n",
    "    f = plt.figure(figsize=(10,3))\n",
    "    plt.specgram(x)\n",
    "    plt.colorbar()\n",
    "    plt.clim(*clim)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `Audio` function above to listen to the signal we will be experimenting with, a simple voice recording stored in the file `hw_0_data/voice.wav`.\n",
    "\n",
    "Note: if your browser doesn't support audio, you may try a different browser.   We've tested current versions of Chrome and Firefox, and it works OK with both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/farahshih/Documents/Codes/Python_For_Data_Science/Fu-Chi/Homework1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homework_1-2.ipynb             \u001b[31mhw_1-3-AudioCompression.ipynb\u001b[m\u001b[m*\r\n",
      "hw_1-1-masked-arrays.ipynb     \u001b[31mhw_1-4-ImageDenoising.ipynb\u001b[m\u001b[m*\r\n",
      "\u001b[31mhw_1-2-crosscorrelation.ipynb\u001b[m\u001b[m* \u001b[31mvoice.wav\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>voice.wav:</p>\n",
       "<audio controls>\n",
       "    <source src=\"files/voice.wav\" type=\"audio/wav\">\n",
       "\n",
       "Your browser does not support the Audio element; you can play \n",
       "<a href=\"files/voice.wav\">this file</a> manually.\n",
       "</audio>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Audio(\"voice.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to compress a 1-d signal by dropping a fraction of its spectrum. \n",
    "\n",
    "You can drop the smallest components by setting their values to zero.\n",
    "\n",
    "*Hints*: \n",
    "\n",
    "- look at the `np.fft` module, keeping in mind that your input signal is real.\n",
    "- look at the `argsort` method of numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compress_signal(x, fraction):\n",
    "    \"\"\"Compress an input signal by dropping a fraction of its spectrum.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x : array\n",
    "      1-d real array to be compressed\n",
    "      \n",
    "    fraction : float\n",
    "      A number in the [0,1] range indicating which fraction of the spectrum\n",
    "      of x should be zeroed out (1 means zero out the entire signal).\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    x_approx : array\n",
    "      1-d real array reconstructed after having compressed the input.\n",
    "    \"\"\"\n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick visual check (not that this is *not* a formal test of correctness), experiment with a simple random signal by changing the compression ratio and plotting both the signal and the compressed version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13021517,  0.38913266,  0.65448311,  0.520014  ,  0.49651866,\n",
       "        0.61906159,  0.45563604,  0.78399817,  0.56229642,  0.5294653 ,\n",
       "        0.51978838,  0.83235519,  0.5353021 ,  0.90449169,  0.13296571,\n",
       "        0.55110005,  0.67302177,  0.67254863,  0.48725501,  0.71335267,\n",
       "        0.66035393,  0.73229647,  0.17003958,  0.70109945,  0.13300045,\n",
       "        0.94325512,  0.37822919,  0.55239791,  0.11271853,  0.66427978,\n",
       "        0.45593381,  0.12149709,  0.42650306,  0.11520903,  0.28034903,\n",
       "        0.5553781 ,  0.65958659,  0.6181334 ,  0.95322366,  0.54746562,\n",
       "        0.72346675,  0.24330527,  0.71827539,  0.75552388,  0.88489523,\n",
       "        0.00160484,  0.95592166,  0.80145447,  0.02143326,  0.91915146,\n",
       "        0.82825406,  0.22476102,  0.42938658,  0.99677007,  0.8661696 ,\n",
       "        0.47481366,  0.4552511 ,  0.13066319,  0.64805203,  0.53903105,\n",
       "        0.78438298,  0.82272163,  0.96219939,  0.38638541,  0.69813942,\n",
       "        0.73148857,  0.74999771,  0.16029279,  0.60448021,  0.10371378,\n",
       "        0.76088912,  0.38176068,  0.08869008,  0.96741066,  0.43346458,\n",
       "        0.90954758,  0.20219599,  0.91414699,  0.43324075,  0.12723942,\n",
       "        0.12116461,  0.96274964,  0.11968199,  0.91825572,  0.65402941,\n",
       "        0.88628303,  0.88721249,  0.21215235,  0.56044213,  0.67204509,\n",
       "        0.59409708,  0.44785709,  0.02144001,  0.32453984,  0.10576043,\n",
       "        0.62649141,  0.06990886,  0.06779757,  0.51521367,  0.53526987,\n",
       "        0.57865206,  0.64479471,  0.04128324,  0.09943856,  0.31117752,\n",
       "        0.86455794,  0.0614642 ,  0.26652897,  0.86769914,  0.53220042,\n",
       "        0.27651789,  0.20562709,  0.57985578,  0.65692283,  0.97854107,\n",
       "        0.96519576,  0.54566183,  0.26937011,  0.53713561,  0.14870657,\n",
       "        0.292221  ,  0.05093704,  0.24950522,  0.96685806,  0.69072592,\n",
       "        0.62326166,  0.58008927,  0.35548693])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compress_signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3ae099e72848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.6\u001b[0m  \u001b[0;31m# play changing this in the 0-1 range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompress_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compress_signal' is not defined"
     ]
    }
   ],
   "source": [
    "fraction = .6  # play changing this in the 0-1 range\n",
    "\n",
    "xa = compress_signal(x, fraction)\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(x, alpha=0.5, lw=2, label='original')\n",
    "plt.plot(xa, lw=2, label='compressed {0:.0%}'.format(fraction))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that will compress an audio file by a dropping a fraction of its spectrum, writing the output to a new file.\n",
    "\n",
    "If the input file is named `a.wav` and the compression fraction is 0.9, the output file should be named `a_comp_0.9.wav`.\n",
    "\n",
    "*Hints:* \n",
    "\n",
    "- look at the `scipy.io` module for routines dealing with files in `wav` format.\n",
    "\n",
    "- you may need to use the `astype` method of numpy arrays to get the correct data type for `wav` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compress_wav(fname, fraction):\n",
    "    \"\"\"Compress an audio signal stored in an input wav file.\n",
    "    \n",
    "    The compressed signal is returned as a numpy array and automatically written \n",
    "    to disk to a new wav file.\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    fname : string\n",
    "      Name of the input wav file\n",
    "      \n",
    "    fraction : float\n",
    "      Fraction of input data to keep.\n",
    "      \n",
    "    Returns\n",
    "    =======\n",
    "    rate : int\n",
    "      Bit rate of the input signal.\n",
    "\n",
    "    x : array\n",
    "      Raw data of the original input signal.\n",
    "      \n",
    "    x_approx : array\n",
    "      Raw data of the compressed signal.\n",
    "      \n",
    "    new_fname : string\n",
    "      Auto-generated filename of the compressed signal.\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the effect of compressing the input file at different ratios: 0.1, 0.5, 0.75, 0.9, 0.95, 0.99.\n",
    "\n",
    "Using the `OrderedDict` class from the [Python collections module](http://docs.python.org/2/library/collections.html#collections.OrderedDict), store the uncompressed signal as well as the compressed array and filename for each compression ratio.\n",
    "\n",
    "You will create an `OrderedDict` called `voices`, with:\n",
    "\n",
    "- keys: compression ratios\n",
    "- values: pairs of (x, filename) where x is the compressed audio and filename is the name of the compressed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over the `voices` dict, and for each one generate an audio player as well as a spectrogram.  Observe how the spectrogram changes, and listen to each file.  At what ratio do you stop understanding the recording?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
